{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_biggan import (BigGAN, one_hot_from_int, truncated_noise_sample,\n",
    "                                       save_as_images, display_in_terminal)\n",
    "\n",
    "model = BigGAN.from_pretrained('biggan-deep-128') # or biggan-deep-256\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def to_pil(out):\n",
    "    img_np = out.detach().cpu().numpy()[0]\n",
    "    img_np = np.clip((img_np + 1) / 2.0 * 255.0, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # C X H X W to H x W x C\n",
    "    img_np = img_np.transpose(1, 2, 0)\n",
    "\n",
    "    return Image.fromarray(img_np)\n",
    "\n",
    "def show(img):\n",
    "    pred = np.clip((img.detach().cpu().squeeze().numpy()+1) / 2.0 * 255, 0, 255)\n",
    "    pred = pred.transpose(1, 2, 0).astype(\"uint8\")\n",
    "    pred = Image.fromarray(pred)\n",
    "    display(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_z(img, G, class_, truncation, lr, num_iter=5000):\n",
    "    # sample tensor\n",
    "    z_ = torch.from_numpy(truncated_noise_sample(truncation=truncation, batch_size=1)).to('cuda')\n",
    "\n",
    "    dist = torch.nn.MSELoss()\n",
    "\n",
    "    # RMSProp or ADAM or SGD\n",
    "    optZ = torch.optim.SGD([z_], lr=lr, momentum=0)\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        img_pred = G(z_, class_, truncation)\n",
    "        loss = dist(img_pred, img)\n",
    "    \n",
    "        if i % 100 == 0:\n",
    "            print(\"[Iter {}] error: {}\"\n",
    "                  .format(i, loss.item()))\n",
    "            show(img_pred)\n",
    "            show(img)\n",
    "            \n",
    "\n",
    "        optZ.zero_grad()\n",
    "        loss.backward()\n",
    "        optZ.step()\n",
    "\n",
    "        # truncate\n",
    "        # z_ = torch.clamp(z_, max=1., min=-1.)\n",
    "\n",
    "    return z_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncation = 0.4  # truncation trick (0-1, larger value will generate more diverse image but the quality is worse)\n",
    "class_vector = one_hot_from_int(250)  # input imagenet label here\n",
    "noise_vector = truncated_noise_sample(truncation=truncation, batch_size=1)\n",
    "\n",
    "noise_vector = torch.from_numpy(noise_vector)\n",
    "class_vector = torch.from_numpy(class_vector)\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "noise_vector = noise_vector.to('cuda')\n",
    "class_vector = class_vector.to('cuda')\n",
    "model.to('cuda')\n",
    "\n",
    "# Generate an image\n",
    "with torch.no_grad():\n",
    "    output = model(noise_vector, class_vector, truncation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inversion or denoising \n",
    "noise_scale = 0.   # set to something larger than 0 for denoising\n",
    "img_gt = torch.clamp(torch.randn_like(output) * noise_scale + output, min=-1, max=1)  \n",
    "\n",
    "# when we can only change latent code z, even in range image's inversion is hard for BigGAN using gradient descent\n",
    "z_pred = find_z(img_gt.detach(), model, class_vector, truncation, lr=1, num_iter=2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
